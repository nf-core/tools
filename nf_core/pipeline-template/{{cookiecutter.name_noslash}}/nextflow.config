/*
 * -------------------------------------------------
 *  {{ cookiecutter.name }} Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

// Global default params, used in configs
params {

  // Container slug. Stable releases should specify release tag!
  // Developmental code should specify :dev
  container = '{{ cookiecutter.name_docker }}:dev'

  // Workflow flags
  // TODO nf-core: Specify your pipeline's command line flags
  reads = "data/*{1,2}.fastq.gz"
  singleEnd = false
  outdir = './results'

  // Boilerplate options
  name = false
  multiqc_config = "$baseDir/conf/multiqc_config.yaml"
  email = false
  plaintext_email = false
  monochrome_logs = false
  help = false
  igenomes_base = "./iGenomes"
  tracedir = "${params.outdir}/pipeline_info"
  clusterOptions = false
  awsqueue = false
  awsregion = 'eu-west-1'
  igenomesIgnore = false
  custom_config_version = 'master'
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
includeConfig "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}/nfcore_custom.config"

profiles {
  awsbatch { includeConfig 'conf/awsbatch.config' }
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    process.container = params.container
  }
  singularity {
    singularity.enabled = true
  }
  test { includeConfig 'conf/test.config' }
}

// Load igenomes.config if required
if(!params.igenomesIgnore){
  includeConfig 'conf/igenomes.config'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

manifest {
  name = '{{ cookiecutter.name }}'
  author = '{{ cookiecutter.author }}'
  homePage = 'https://github.com/{{ cookiecutter.name }}'
  description = '{{ cookiecutter.description }}'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = '{{ cookiecutter.version }}'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
